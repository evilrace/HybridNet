{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data.dataset as dataset\n",
    "\n",
    "from models.model import HybridNet\n",
    "from utils.anchors import Anchor\n",
    "from utils.labels import get_detection_labels\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_class_num = 8\n",
    "\n",
    "detection_datset = dataset.DetectionDataset()\n",
    "segment_dataset = dataset.SegmentDataset()\n",
    "anchor_generator = Anchor((375,1242))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transform = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.Resize(512, interpolation=torchvision.transforms.InterpolationMode.NEAREST)]\n",
    ")\n",
    "\n",
    "def detection_rescale(X):\n",
    "    img_batch = []\n",
    "    label_batch = []\n",
    "    for img, label in X:\n",
    "        c, h, w = img.size()\n",
    "        scale_h = h / 375\n",
    "        scale_w = h / 1242\n",
    "        scale = torch.tensor([1, scale_w, scale_h, scale_w, scale_h])\n",
    "        label = label * scale\n",
    "        img = torchvision.transforms.Resize((375,1242))(img)\n",
    "        img_batch.append(img)\n",
    "        labels = []\n",
    "        for anchor in anchor_generator.anchors_list[-6:]:\n",
    "            label_ = get_detection_labels(label, anchor)\n",
    "            labels.append(label_)\n",
    "\n",
    "        labels = torch.concat(labels, dim=0)\n",
    "        label_batch.append(labels)\n",
    "    return torch.stack(img_batch,dim=0), torch.stack(label_batch,dim=0)\n",
    "\n",
    "\n",
    "def segmentation_rescale(X):\n",
    "    img_batch = []\n",
    "    label_batch = []\n",
    "    for img, label in X:\n",
    "        img = img_transform(img)\n",
    "        label = img_transform(label)\n",
    "        img_batch.append(img)\n",
    "        label_batch.append(label)\n",
    "    return torch.stack(img_batch,dim=0), torch.stack(label_batch,dim=0)\n",
    "\n",
    "detection_dataloader = torch.utils.data.DataLoader(detection_datset, batch_size=8, shuffle=True, collate_fn = detection_rescale)\n",
    "segment_dataloader = torch.utils.data.DataLoader(segment_dataset, batch_size=8, shuffle=True, collate_fn = segmentation_rescale)\n",
    "\n",
    "torch.save(detection_dataloader, \"detection_dataset.pt\")\n",
    "torch.save(segment_dataloader, \"segment_dataset.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_dataloader = torch.load(\"detection_dataset.pt\")\n",
    "segment_dataloader = torch.load(\"segment_dataset.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = HybridNet(128, anchor_generator.anchor_nums, detection_class_num)\n",
    "net = net.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # run training\n",
    "# import tqdm\n",
    "# import gc\n",
    "# loss_fn = torch.nn.BCELoss()\n",
    "# optimizer = torch.optim.Adam(net.parameters())\n",
    "\n",
    "# torch.cuda.empty_cache()\n",
    "# gc.collect()\n",
    "\n",
    "# for i in range(5):\n",
    "#     pbar = tqdm.tqdm(total = len(segment_dataloader))\n",
    "#     accum = [0] * 2\n",
    "#     for batch in segment_dataloader:\n",
    "#         X, y = batch\n",
    "#         y = torch.where(y==7, 1, 0)\n",
    "#         y = y.float()\n",
    "#         X = X.to('cuda')\n",
    "#         X = X / 255.0\n",
    "#         pred = net(X)\n",
    "#         pred = pred[0].to('cpu')\n",
    "#         loss = loss_fn(pred, y)\n",
    "#         pred = torch.where(pred > 0.5, 1, 0)\n",
    "#         acc = (pred == y).to(torch.uint8)\n",
    "#         accum[0] = accum[0] + torch.sum(acc)\n",
    "#         accum[1] = accum[1] + (acc.size()[0]*acc.size()[1]*acc.size()[2]*acc.size()[3])\n",
    "#         acc = accum[0] / accum[1]\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         pbar.set_description(f\"loss:{loss:.3f}, acc:{acc*100:.3f}%\")\n",
    "#         pbar.update()\n",
    "#     pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss:1.840: 100%|██████████| 936/936 [18:52<00:00,  1.21s/it]\n",
      "loss:1.847: 100%|██████████| 936/936 [15:24<00:00,  1.01it/s]\n",
      "loss:1.665: 100%|██████████| 936/936 [15:24<00:00,  1.01it/s]\n",
      "loss:1.379: 100%|██████████| 936/936 [15:22<00:00,  1.01it/s]\n",
      "loss:1.469: 100%|██████████| 936/936 [15:21<00:00,  1.02it/s]\n",
      "loss:1.108: 100%|██████████| 936/936 [15:23<00:00,  1.01it/s]\n",
      "loss:0.916: 100%|██████████| 936/936 [15:21<00:00,  1.02it/s]\n",
      "loss:1.748: 100%|██████████| 936/936 [15:22<00:00,  1.01it/s]\n",
      "loss:0.895: 100%|██████████| 936/936 [15:22<00:00,  1.02it/s]\n",
      "loss:1.515: 100%|██████████| 936/936 [15:28<00:00,  1.01it/s]\n",
      "loss:0.802: 100%|██████████| 936/936 [15:25<00:00,  1.01it/s]\n",
      "loss:0.577: 100%|██████████| 936/936 [15:27<00:00,  1.01it/s]\n",
      "loss:nan: 100%|██████████| 936/936 [15:37<00:00,  1.00s/it]  \n",
      "loss:nan: 100%|██████████| 936/936 [15:33<00:00,  1.00it/s]\n",
      "loss:nan: 100%|██████████| 936/936 [15:29<00:00,  1.01it/s]\n",
      "loss:nan: 100%|██████████| 936/936 [15:34<00:00,  1.00it/s]\n",
      "loss:nan: 100%|██████████| 936/936 [15:32<00:00,  1.00it/s]\n",
      "loss:nan: 100%|██████████| 936/936 [15:33<00:00,  1.00it/s]\n",
      "loss:nan: 100%|██████████| 936/936 [15:32<00:00,  1.00it/s]\n",
      "loss:nan: 100%|██████████| 936/936 [15:13<00:00,  1.02it/s]\n"
     ]
    }
   ],
   "source": [
    "from loss.detection_loss import det_loss\n",
    "loss = det_loss(detection_class_num)\n",
    "optimizer = torch.optim.Adam(net.parameters())\n",
    "\n",
    "for i in range(10):\n",
    "    pbar = tqdm.tqdm(total = len(detection_dataloader))\n",
    "    accum = [0] * 2\n",
    "    for batch in detection_dataloader:\n",
    "        X, y = batch\n",
    "        X = X.to('cuda')\n",
    "        X = X / 255.0\n",
    "        pred = net(X)\n",
    "        score = loss(pred[1], y)\n",
    "        optimizer.zero_grad()\n",
    "        score.backward()\n",
    "        optimizer.step()\n",
    "        pbar.set_description(f\"loss:{score:.3f}\")\n",
    "        pbar.update()\n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [8], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m output \u001b[39m=\u001b[39m net(sample)\n\u001b[0;32m     13\u001b[0m output \u001b[39m=\u001b[39m output[\u001b[39m1\u001b[39m]\n\u001b[1;32m---> 14\u001b[0m output \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39;49mto(\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     15\u001b[0m output \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mpermute(output, (\u001b[39m0\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m3\u001b[39m,\u001b[39m1\u001b[39m))\n\u001b[0;32m     16\u001b[0m output \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "\n",
    "torch.save(detection_dataloader, 'detection_dataset.pt')\n",
    "torch.save(segment_dataloader, 'segmentation_dataset.pt')\n",
    "\n",
    "net = torch.save(net, 'trained_model.pth')\n",
    "net = torch.load(\"trained_model.pth\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "sample = next(iter(segment_dataloader))\n",
    "sample = sample[0]\n",
    "sample = sample.to('cuda')\n",
    "sample = sample.to(torch.float32)\n",
    "output = net(sample)\n",
    "output = output[1]\n",
    "output = output.to('cpu')\n",
    "output = torch.permute(output, (0,2,3,1))\n",
    "output = output.detach().numpy()\n",
    "\n",
    "fig, axes = plt.subplots(3,3)\n",
    "fig.set_size_inches(16,16)\n",
    "\n",
    "sample = sample.to('cpu').to(torch.uint8)\n",
    "sample = torch.permute(sample, (0,2,3,1))\n",
    "for i in range(8):\n",
    "    axes[i//3, i%3].imshow(sample[i])\n",
    "\n",
    "fig, axes = plt.subplots(3,3)\n",
    "for i in range(8):\n",
    "    axes[i//3, i%3].imshow(output[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f5f227904729d2e34638b12d6189826106a201c215150695c35e0f334bf03903"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
